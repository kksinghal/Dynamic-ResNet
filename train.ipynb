{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e327ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from brain import Agent\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cpu\"#torch.device(\"cuda\")\n",
    "max_iterations = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b765fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    torch.manual_seed(seed)  # Sets seed for PyTorch RNG\n",
    "    torch.cuda.manual_seed_all(seed)  # Sets seeds of GPU RNG\n",
    "    np.random.seed(seed=seed)  # Set seed for NumPy RNG\n",
    "    random.seed(seed)  # Set seed for random RNG\n",
    "\n",
    "set_seeds(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0d17ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    " ])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    " ])\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "trainset = CIFAR10(\"../data\", train=True, transform=train_transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "valset = CIFAR10(\"../data\", train=False, transform=val_transform, download=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, shuffle=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79745249",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Agent(max_iterations).to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "lr=1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)#, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f61901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intern_1/Desktop/Dynamic-ResNet/brain.py:44: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  batch_size = int(c1.shape[0]/64)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"tensorboard\")\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "writer.add_graph(model, images.to(device))\n",
    "writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99028769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    trainloss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_compute_cost = []\n",
    "\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "        model = model.train()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        probs_each_iteration = model(X) #max_iterations, batch_size, n_classes\n",
    "        loss = 0\n",
    "        for i in range(probs_each_iteration.shape[0]):\n",
    "            probs = probs_each_iteration[i]\n",
    "            loss += (0.5**i) * loss_fn(torch.log(probs), y)\n",
    "\n",
    "        iteration_max_prob, _ = torch.max(probs_each_iteration, dim=2) #max_iterations, batch_size\n",
    "        iteration_where_pred_made = (iteration_max_prob > 0.5).nonzero(as_tuple=True)[0].view(max_iterations, batch_size)[0] #batch_size\n",
    "        train_compute_cost.append(iteration_where_pred_made)\n",
    "\n",
    "        pred = torch.argmax(probs_each_iteration[iteration_where_pred_made, range(batch_size)], dim=1)\n",
    "\n",
    "        trainloss += loss.item()\n",
    "\n",
    "        train_total += len(pred)\n",
    "        train_correct += (pred == y).sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    valloss = 0\n",
    "    val_compute_cost = []\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (X,y) in enumerate(val_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            probs_each_iteration = model(X) #max_iterations, batch_size, n_classes\n",
    "            valloss = 0\n",
    "            for i in range(probs_each_iteration.shape[0]):\n",
    "                probs = probs_each_iteration[i]\n",
    "                valloss += (0.5**i) * loss_fn(torch.log(probs), y)\n",
    "\n",
    "            iteration_max_prob, _ = torch.max(probs_each_iteration, dim=2) #max_iterations, batch_size\n",
    "            iteration_where_pred_made = (iteration_max_prob > 0.5).nonzero(as_tuple=True)[0].view(max_iterations, batch_size)[0] #batch_size\n",
    "            val_compute_cost.append(iteration_where_pred_made)\n",
    "            pred = torch.argmax(probs_each_iteration[iteration_where_pred_made, range(batch_size)], dim=1)\n",
    "\n",
    "            val_total += len(pred)\n",
    "            val_correct += (pred == y).sum().item()\n",
    "\n",
    "    print(f\"Epoch: {epoch}; Train Loss: {trainloss/train_total}, Val Loss: {valloss/val_total}\")\n",
    "\n",
    "    writer.add_scalars(\"Training vs Validation Accuracy\", {\n",
    "        \"training\": train_correct/train_total,\n",
    "        \"validation\": val_correct/val_total\n",
    "    }, epoch)\n",
    "\n",
    "    writer.add_scalars(\"Training vs Validation loss\", {\n",
    "        \"training\": trainloss/train_total,\n",
    "        \"validation\": valloss/val_total\n",
    "    }, epoch)\n",
    "\n",
    "    writer.add_scalars(\"Training vs Validation Compute Cost\", {\n",
    "        \"training\": train_compute_cost.sum()/train_total.numel(),\n",
    "        \"validation\": val_compute_cost.sum()/val_total.numel()\n",
    "    }, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54968e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = torch.load(\"model\")\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#checkpoint[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c16b6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for g in optimizer.param_groups:\n",
    "#    g['weight_decay'] = 0.0011\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "697e6ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1563 [00:54<11:51:38, 27.35s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for t in range(0, epochs):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = max(lr*(0.997**t), 0.5*lr)\n",
    "        #g['weight_'] = lr*0.5\n",
    "    train_loop(train_loader, model, loss_fn, optimizer, epoch=t)\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': t\n",
    "            }, \"model\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0e258a8abb4dfe9b940c7c951b2a61d2696e67433b3ab905ee2e517e6cd2af1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('cl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
