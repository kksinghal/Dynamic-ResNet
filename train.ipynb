{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b7f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from brain import Agent\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14910450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    torch.manual_seed(seed)  # Sets seed for PyTorch RNG\n",
    "    torch.cuda.manual_seed_all(seed)  # Sets seeds of GPU RNG\n",
    "    np.random.seed(seed=seed)  # Set seed for NumPy RNG\n",
    "    random.seed(seed)  # Set seed for random RNG\n",
    "\n",
    "set_seeds(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52928373",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    " ])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    " ])\n",
    "\n",
    "batch_size=192\n",
    "\n",
    "trainset = CIFAR10(\"../data\", train=True, transform=train_transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=batch_size, drop_last=True, num_workers=3, pin_memory=True)\n",
    "\n",
    "valset = CIFAR10(\"../data\", train=False, transform=val_transform, download=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, shuffle=False, batch_size=batch_size, drop_last=True, num_workers=3, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Agent().to(device)\n",
    "model2 = Agent().to(device)\n",
    "model2.load_state_dict(model.state_dict())\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "lr=1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#                optimizer, factor=0.2, mode=\"max\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"tensorboard\")\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "writer.add_graph(model, images.to(device))\n",
    "writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch, dropout_p):\n",
    "    size = len(dataloader.dataset)\n",
    "    trainloss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "        model.train()\n",
    "        model2.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        model = model.train()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X, dropout_p)\n",
    "        loss = loss_fn(pred, y)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "\n",
    "        trainloss += loss.item()\n",
    "\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        train_total += len(pred)\n",
    "        train_correct += (pred == y).sum().item()\n",
    "    \n",
    "    \n",
    "        for i, (X,y) in enumerate(val_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model2(X)\n",
    "            valloss = loss_fn(pred, y)\n",
    "            valloss.backward()\n",
    "            break\n",
    "        \n",
    "        for p1, p2 in zip(model.parameters(), model2.parameters()):\n",
    "            p1.grad = torch.where(p1.grad*p2.grad > 0, p1.grad, p1.grad/100)\n",
    "            print((p1.grad*p2.grad > 0).sum()/torch.numel(p1.grad))\n",
    "        \n",
    "        optimizer.step()\n",
    "        model2.load_state_dict(model.state_dict())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    model2.eval()\n",
    "    valloss = 0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    for i, (X,y) in enumerate(val_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model2(X)\n",
    "        valloss += loss_fn(pred, y).item()\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        val_total += len(pred)\n",
    "        val_correct += (pred == y).sum().item()\n",
    "        \n",
    "    \n",
    "    print(f\"Epoch: {epoch}; Train Loss: {trainloss/train_total}, Val Loss: {valloss/val_total}\")\n",
    "\n",
    "    writer.add_scalars(\"Training vs Validation Accuracy\", {\n",
    "        \"training\": train_correct/train_total,\n",
    "        \"validation\": val_correct/val_total\n",
    "    }, epoch)\n",
    "\n",
    "    writer.add_scalars(\"Training vs Validation loss\", {\n",
    "        \"training\": trainloss/train_total,\n",
    "        \"validation\": valloss/val_total\n",
    "    }, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = torch.load(\"model\")\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "#last_epoch = checkpoint[\"epoch\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82f64b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "for t in range(0, epochs):\n",
    "    dropout_p = 0.3\n",
    "    train_loop(train_loader, model, loss_fn, optimizer, epoch=t, dropout_p=dropout_p)\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        #'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'epoch': t\n",
    "        }, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd143f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
